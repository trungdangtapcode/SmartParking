"""
üîç So s√°nh ch·∫•t l∆∞·ª£ng ·∫£nh: test-image.png vs ·∫£nh t·ª´ stream
Ph√¢n t√≠ch s·ª± kh√°c bi·ªát v·ªÅ ch·∫•t l∆∞·ª£ng ·∫£nh
"""
import cv2
import numpy as np
import sys
import os
from pathlib import Path
import base64


def analyze_image_quality(image, image_name="Image"):
    """
    Ph√¢n t√≠ch chi ti·∫øt ch·∫•t l∆∞·ª£ng ·∫£nh
    """
    if image is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc {image_name}")
        return None
    
    h, w = image.shape[:2]
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Basic metrics
    brightness = np.mean(gray)
    contrast = np.std(gray)
    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
    
    # Histogram analysis
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    hist_percent = hist / hist.sum() * 100
    
    over_exposed = np.sum(hist_percent[200:])
    under_exposed = np.sum(hist_percent[:50])
    well_exposed = np.sum(hist_percent[50:200])
    
    # Edge detection ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô s·∫Øc n√©t
    edges = cv2.Canny(gray, 50, 150)
    edge_density = np.sum(edges > 0) / (w * h) * 100
    
    # Color analysis
    b, g, r = cv2.split(image)
    color_saturation = np.std([b, g, r], axis=0).mean()
    
    # Noise estimation (variance of Laplacian)
    noise_level = cv2.Laplacian(gray, cv2.CV_64F).var()
    
    # Contrast ratio (max/min)
    min_val = np.min(gray)
    max_val = np.max(gray)
    contrast_ratio = max_val / max(min_val, 1)
    
    return {
        'name': image_name,
        'size': f"{w}x{h}",
        'width': w,
        'height': h,
        'total_pixels': w * h,
        'brightness': brightness,
        'contrast': contrast,
        'sharpness': sharpness,
        'noise_level': noise_level,
        'edge_density': edge_density,
        'color_saturation': color_saturation,
        'contrast_ratio': contrast_ratio,
        'over_exposed': over_exposed,
        'under_exposed': under_exposed,
        'well_exposed': well_exposed,
        'histogram': hist_percent.flatten(),
    }


def compare_images(img1_path, img2_path=None, img2_base64=None):
    """
    So s√°nh 2 ·∫£nh
    """
    print("=" * 80)
    print("üîç PH√ÇN T√çCH CH·∫§T L∆Ø·ª¢NG ·∫¢NH")
    print("=" * 80)
    
    # Load image 1 (test image)
    if not os.path.exists(img1_path):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {img1_path}")
        return
    
    img1 = cv2.imread(img1_path)
    if img1 is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc: {img1_path}")
        return
    
    q1 = analyze_image_quality(img1, "Test Image (test-image.png)")
    
    # Load image 2 (from stream or file)
    img2 = None
    q2 = None
    
    if img2_path and os.path.exists(img2_path):
        img2 = cv2.imread(img2_path)
        if img2 is not None:
            q2 = analyze_image_quality(img2, "Stream Image")
    elif img2_base64:
        try:
            # Decode base64
            if "," in img2_base64:
                img2_base64 = img2_base64.split(",", 1)[1]
            
            image_bytes = base64.b64decode(img2_base64)
            np_array = np.frombuffer(image_bytes, dtype=np.uint8)
            img2 = cv2.imdecode(np_array, cv2.IMREAD_COLOR)
            
            if img2 is not None:
                q2 = analyze_image_quality(img2, "Stream Image (from base64)")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ decode base64: {e}")
    
    # Print analysis
    print(f"\nüìä CH·∫§T L∆Ø·ª¢NG ·∫¢NH 1: {q1['name']}")
    print(f"{'‚îÄ' * 80}")
    print(f"  K√≠ch th∆∞·ªõc:        {q1['size']} ({q1['total_pixels']:,} pixels)")
    print(f"  Brightness:        {q1['brightness']:.1f} / 255")
    print(f"    ‚Üí {'‚úÖ T·ªët' if 100 <= q1['brightness'] <= 150 else '‚ö†Ô∏è Qu√° t·ªëi' if q1['brightness'] < 100 else '‚ö†Ô∏è Qu√° s√°ng'}")
    print(f"  Contrast:          {q1['contrast']:.1f}")
    print(f"    ‚Üí {'‚úÖ T·ªët' if q1['contrast'] > 40 else '‚ö†Ô∏è Thi·∫øu t∆∞∆°ng ph·∫£n'}")
    print(f"  Sharpness:         {q1['sharpness']:.2f}")
    print(f"    ‚Üí {'‚úÖ S·∫Øc n√©t' if q1['sharpness'] > 100 else '‚ö†Ô∏è B·ªã m·ªù'}")
    print(f"  Noise Level:       {q1['noise_level']:.2f}")
    print(f"  Edge Density:      {q1['edge_density']:.2f}%")
    print(f"  Color Saturation:  {q1['color_saturation']:.1f}")
    print(f"  Contrast Ratio:    {q1['contrast_ratio']:.1f}:1")
    print(f"  Exposure:")
    print(f"    - Over-exposed:  {q1['over_exposed']:.1f}%")
    print(f"    - Well-exposed:  {q1['well_exposed']:.1f}%")
    print(f"    - Under-exposed: {q1['under_exposed']:.1f}%")
    
    if q2:
        print(f"\nüìä CH·∫§T L∆Ø·ª¢NG ·∫¢NH 2: {q2['name']}")
        print(f"{'‚îÄ' * 80}")
        print(f"  K√≠ch th∆∞·ªõc:        {q2['size']} ({q2['total_pixels']:,} pixels)")
        print(f"  Brightness:        {q2['brightness']:.1f} / 255")
        print(f"    ‚Üí {'‚úÖ T·ªët' if 100 <= q2['brightness'] <= 150 else '‚ö†Ô∏è Qu√° t·ªëi' if q2['brightness'] < 100 else '‚ö†Ô∏è Qu√° s√°ng'}")
        print(f"  Contrast:          {q2['contrast']:.1f}")
        print(f"    ‚Üí {'‚úÖ T·ªët' if q2['contrast'] > 40 else '‚ö†Ô∏è Thi·∫øu t∆∞∆°ng ph·∫£n'}")
        print(f"  Sharpness:         {q2['sharpness']:.2f}")
        print(f"    ‚Üí {'‚úÖ S·∫Øc n√©t' if q2['sharpness'] > 100 else '‚ö†Ô∏è B·ªã m·ªù'}")
        print(f"  Noise Level:       {q2['noise_level']:.2f}")
        print(f"  Edge Density:      {q2['edge_density']:.2f}%")
        print(f"  Color Saturation:  {q2['color_saturation']:.1f}")
        print(f"  Contrast Ratio:    {q2['contrast_ratio']:.1f}:1")
        print(f"  Exposure:")
        print(f"    - Over-exposed:  {q2['over_exposed']:.1f}%")
        print(f"    - Well-exposed:  {q2['well_exposed']:.1f}%")
        print(f"    - Under-exposed: {q2['under_exposed']:.1f}%")
        
        # Comparison
        print(f"\nüìà SO S√ÅNH")
        print(f"{'‚îÄ' * 80}")
        
        # Size comparison
        size_diff = abs(q1['total_pixels'] - q2['total_pixels']) / max(q1['total_pixels'], q2['total_pixels']) * 100
        print(f"  K√≠ch th∆∞·ªõc:        {size_diff:.1f}% kh√°c bi·ªát")
        if size_diff > 20:
            print(f"    ‚ö†Ô∏è Kh√°c bi·ªát l·ªõn v·ªÅ k√≠ch th∆∞·ªõc!")
        
        # Brightness comparison
        brightness_diff = abs(q1['brightness'] - q2['brightness'])
        print(f"  Brightness:        Ch√™nh l·ªách {brightness_diff:.1f}")
        if brightness_diff > 30:
            print(f"    ‚ö†Ô∏è Kh√°c bi·ªát l·ªõn v·ªÅ ƒë·ªô s√°ng!")
            if q2['brightness'] < q1['brightness']:
                print(f"    üí° Stream image qu√° t·ªëi h∆°n test image")
            else:
                print(f"    üí° Stream image qu√° s√°ng h∆°n test image")
        
        # Contrast comparison
        contrast_diff = abs(q1['contrast'] - q2['contrast'])
        print(f"  Contrast:          Ch√™nh l·ªách {contrast_diff:.1f}")
        if contrast_diff > 10:
            print(f"    ‚ö†Ô∏è Kh√°c bi·ªát v·ªÅ ƒë·ªô t∆∞∆°ng ph·∫£n!")
            if q2['contrast'] < q1['contrast']:
                print(f"    üí° Stream image thi·∫øu t∆∞∆°ng ph·∫£n h∆°n")
        
        # Sharpness comparison
        sharpness_diff = abs(q1['sharpness'] - q2['sharpness'])
        sharpness_ratio = q2['sharpness'] / max(q1['sharpness'], 1)
        print(f"  Sharpness:         Stream = {sharpness_ratio * 100:.1f}% c·ªßa test image")
        if sharpness_ratio < 0.7:
            print(f"    ‚ö†Ô∏è Stream image B·ªä M·ªú H∆†N nhi·ªÅu!")
            print(f"    üí° C·∫ßn sharpen preprocessing")
        elif sharpness_ratio > 1.3:
            print(f"    ‚úÖ Stream image s·∫Øc n√©t h∆°n")
        
        # Noise comparison
        noise_ratio = q2['noise_level'] / max(q1['noise_level'], 1)
        print(f"  Noise Level:       Stream = {noise_ratio * 100:.1f}% c·ªßa test image")
        if noise_ratio > 1.5:
            print(f"    ‚ö†Ô∏è Stream image c√≥ NHI·ªÄU NHI·ªÑU H∆†N!")
            print(f"    üí° C·∫ßn denoise preprocessing")
        
        # Edge density comparison
        edge_ratio = q2['edge_density'] / max(q1['edge_density'], 0.01)
        print(f"  Edge Density:      Stream = {edge_ratio * 100:.1f}% c·ªßa test image")
        if edge_ratio < 0.7:
            print(f"    ‚ö†Ô∏è Stream image √≠t chi ti·∫øt h∆°n (c√≥ th·ªÉ b·ªã m·ªù)")
        
        # Recommendations
        print(f"\nüí° KHUY·∫æN NGH·ªä")
        print(f"{'‚îÄ' * 80}")
        recommendations = []
        
        if q2['brightness'] < q1['brightness'] - 20:
            recommendations.append("‚úÖ Th√™m brightness preprocessing cho stream image")
        
        if q2['contrast'] < q1['contrast'] - 10:
            recommendations.append("‚úÖ Th√™m contrast preprocessing cho stream image")
        
        if q2['sharpness'] < q1['sharpness'] * 0.7:
            recommendations.append("‚úÖ Th√™m sharpen preprocessing cho stream image")
        
        if q2['noise_level'] > q1['noise_level'] * 1.5:
            recommendations.append("‚úÖ Th√™m denoise preprocessing cho stream image")
        
        if q2['total_pixels'] < q1['total_pixels'] * 0.8:
            recommendations.append("‚úÖ Upscale stream image tr∆∞·ªõc khi OCR")
        
        if not recommendations:
            print("  ‚úÖ Ch·∫•t l∆∞·ª£ng ·∫£nh stream t∆∞∆°ng ƒë∆∞∆°ng test image")
        else:
            for rec in recommendations:
                print(f"  {rec}")
    
    return q1, q2


def main():
    if len(sys.argv) < 2:
        print("Usage:")
        print("  python compare_image_quality.py <test_image_path> [stream_image_path]")
        print("")
        print("Examples:")
        print("  python compare_image_quality.py test-image.png")
        print("  python compare_image_quality.py test-image.png stream_capture.jpg")
        sys.exit(1)
    
    test_image = sys.argv[1]
    stream_image = sys.argv[2] if len(sys.argv) > 2 else None
    
    compare_images(test_image, stream_image)


if __name__ == "__main__":
    main()

