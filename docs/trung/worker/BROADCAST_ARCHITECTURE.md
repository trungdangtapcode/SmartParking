# Broadcast Architecture: Real-time Detection Streaming

## Overview
This document details the real-time broadcast architecture that delivers detection frames from the worker to multiple frontend viewers using HTTP POST and WebSocket protocols.

## Table of Contents
1. [Architecture Overview](#architecture-overview)
2. [Worker Broadcasting Layer](#worker-broadcasting-layer)
3. [FastAPI Server Layer](#fastapi-server-layer)
4. [Detection Broadcaster Service](#detection-broadcaster-service)
5. [Frontend Viewer Layer](#frontend-viewer-layer)
6. [Message Formats](#message-formats)
7. [Performance Optimization](#performance-optimization)
8. [Error Handling](#error-handling)

---

## Architecture Overview

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        BROADCAST SYSTEM                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Camera 1   ‚îÇ                  ‚îÇ   Camera 2       ‚îÇ
‚îÇ   ESP32      ‚îÇ                  ‚îÇ   ESP32          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                                   ‚îÇ
       ‚îÇ HTTP (MJPEG Stream)               ‚îÇ
       ‚Üì                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PARKING MONITOR WORKER                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Fetch     ‚îÇ‚Üí ‚îÇ  ByteTrack ‚îÇ‚Üí ‚îÇ   Draw Annotations   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Frames    ‚îÇ  ‚îÇ  Tracking  ‚îÇ  ‚îÇ   (Boxes, Trails)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                              ‚îÇ                ‚îÇ
‚îÇ                                              ‚Üì                ‚îÇ
‚îÇ                                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                                   ‚îÇ  Encode Frame (JPEG) ‚îÇ   ‚îÇ
‚îÇ                                   ‚îÇ  Create Metadata     ‚îÇ   ‚îÇ
‚îÇ                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                 ‚îÇ
                                                 ‚îÇ HTTP POST
                                                 ‚îÇ /api/broadcast-detection
                                                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FASTAPI SERVER                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           Broadcast Detection Endpoint                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Receive frame + metadata from worker                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Decode base64 image                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Store in DetectionBroadcaster                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                             ‚îÇ                                  ‚îÇ
‚îÇ                             ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         DETECTION BROADCASTER SERVICE                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Camera 1 Broadcaster                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ current_frame                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ metadata                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ viewers: [WebSocket1, WebSocket2, WebSocket3]       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Camera 2 Broadcaster                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ current_frame                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ metadata                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ viewers: [WebSocket4, WebSocket5]                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                             ‚îÇ                                  ‚îÇ
‚îÇ                             ‚îÇ WebSocket                        ‚îÇ
‚îÇ                             ‚îÇ /ws/viewer/detection             ‚îÇ
‚îÇ                             ‚Üì                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                 ‚îÇ                 ‚îÇ
            ‚Üì                 ‚Üì                 ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Viewer 1  ‚îÇ    ‚îÇ  Viewer 2  ‚îÇ    ‚îÇ  Viewer 3  ‚îÇ
    ‚îÇ  (React)   ‚îÇ    ‚îÇ  (React)   ‚îÇ    ‚îÇ  (React)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Communication Protocols

1. **Camera ‚Üí Worker:** HTTP (MJPEG)
2. **Worker ‚Üí FastAPI:** HTTP POST (JSON with base64 frame)
3. **FastAPI ‚Üí Viewers:** WebSocket (JSON with base64 frame)
4. **Viewers ‚Üí FastAPI:** WebSocket (ping/pong keepalive)

---

## Worker Broadcasting Layer

### 1. Frame Preparation

**File:** `server/parking_monitor_worker.py:process_camera()`

```python
async def process_camera(self, camera_info: Dict):
    camera_id = camera_info['id']
    camera_url = camera_info['url']
    
    try:
        # 1. Fetch raw frame from camera
        frame_bytes = await self.fetch_camera_frame(camera_url)
        if not frame_bytes:
            return
        
        # 2. Decode to numpy array
        nparr = np.frombuffer(frame_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        # 3. Get parking spaces
        spaces = self.camera_spaces_cache.get(camera_id, [])
        
        # 4. Run detection/tracking
        detections = await self.detect_vehicles_in_frame(frame)
        
        # 5. Match to parking spaces
        space_occupancy = self.parking_service.match_detections_to_spaces(
            detections, spaces, frame.shape[1], frame.shape[0]
        )
        
        # 6. Draw annotations
        annotated_frame = self.draw_detections_on_frame(
            frame, detections, spaces, space_occupancy,
            frame.shape[1], frame.shape[0]
        )
        
        # 7. Create metadata
        metadata = {
            "vehicle_count": len(detections),
            "occupied_spaces": sum(space_occupancy.values()),
            "total_spaces": len(spaces),
            "timestamp": datetime.now().isoformat(),
            "track_ids": [d.get('track_id') for d in detections if 'track_id' in d]
        }
        
        # 8. Broadcast to viewers
        await self.broadcast_frame_to_viewers(
            camera_id, annotated_frame, metadata
        )
        
        # 9. Log detection (async, non-blocking)
        if self.enable_logging:
            await detection_logger.log_detection(
                camera_id=camera_id,
                detections=detections,
                space_occupancy=space_occupancy,
                metadata=metadata
            )
    
    except Exception as e:
        logger.error(f"Error processing camera {camera_id}: {e}")
```

### 2. Frame Encoding and Broadcasting

**File:** `server/parking_monitor_worker.py:broadcast_frame_to_viewers()`

```python
async def broadcast_frame_to_viewers(
    self, 
    camera_id: str, 
    frame: np.ndarray, 
    metadata: dict
):
    """
    Send annotated frame to FastAPI server for broadcasting
    
    Args:
        camera_id: Camera identifier
        frame: Annotated OpenCV frame (numpy array)
        metadata: Detection statistics
    
    Flow:
        1. Encode frame to JPEG
        2. Convert to base64 string
        3. Send HTTP POST to FastAPI
        4. FastAPI broadcasts to WebSocket viewers
    """
    import cv2
    import base64
    import aiohttp
    
    try:
        # 1. Encode frame to JPEG (quality: 85%)
        encode_start = time.time()
        success, buffer = cv2.imencode(
            '.jpg', 
            frame, 
            [cv2.IMWRITE_JPEG_QUALITY, 85]
        )
        
        if not success:
            logger.error(f"Failed to encode frame for camera {camera_id}")
            return
        
        encode_time = (time.time() - encode_start) * 1000
        logger.debug(f"üé® Encoded frame in {encode_time:.1f}ms")
        
        # 2. Convert to base64 string
        frame_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # 3. Prepare payload
        payload = {
            'camera_id': camera_id,
            'frame_base64': frame_base64,
            'metadata': metadata
        }
        
        # 4. Send to FastAPI server
        broadcast_start = time.time()
        
        async with aiohttp.ClientSession() as session:
            broadcast_url = f'{self.detection_url}/api/broadcast-detection'
            
            async with session.post(
                broadcast_url,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=5.0)  # 5 second timeout
            ) as response:
                broadcast_time = (time.time() - broadcast_start) * 1000
                
                if response.status == 200:
                    result = await response.json()
                    viewer_count = result.get('viewers', 0)
                    
                    logger.debug(
                        f"üì∫ Sent frame to {viewer_count} viewers "
                        f"(camera {camera_id}) in {broadcast_time:.1f}ms"
                    )
                else:
                    error_text = await response.text()
                    logger.warning(
                        f"Failed to broadcast frame: HTTP {response.status} - {error_text}"
                    )
    
    except asyncio.TimeoutError:
        logger.warning(
            f"‚è±Ô∏è Timeout broadcasting frame for camera {camera_id} "
            f"(took > 5 seconds)"
        )
    
    except aiohttp.ClientError as e:
        logger.error(f"‚ùå Network error broadcasting frame: {e}")
    
    except Exception as e:
        logger.error(f"‚ùå Error broadcasting frame for camera {camera_id}: {e}")
```

### 3. Performance Metrics

**Timing Breakdown:**
```
Total Frame Processing: ~100ms
‚îú‚îÄ Fetch from camera: 10-20ms
‚îú‚îÄ Decode image: 2-5ms
‚îú‚îÄ YOLO detection/tracking: 45-60ms (GPU)
‚îú‚îÄ Draw annotations: 5-10ms
‚îú‚îÄ Encode to JPEG: 8-12ms
‚îú‚îÄ Base64 encode: 1-2ms
‚îî‚îÄ HTTP POST to FastAPI: 3-8ms
```

**Optimization:**
- JPEG quality: 85% (balance size vs quality)
- Timeout: 5 seconds (prevent blocking)
- Async HTTP: Non-blocking I/O

---

## FastAPI Server Layer

### 1. Broadcast Endpoint

**File:** `server/routers/worker_broadcast.py`

```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import base64
import logging

router = APIRouter(prefix="/api", tags=["Worker Broadcast"])
logger = logging.getLogger(__name__)


class BroadcastRequest(BaseModel):
    """Request model for broadcasting detection frame"""
    camera_id: str
    frame_base64: str  # Base64 encoded JPEG
    metadata: dict


@router.post("/broadcast-detection")
async def broadcast_detection(request: BroadcastRequest):
    """
    Receive detection frame from worker and broadcast to viewers
    
    Flow:
        1. Worker sends frame + metadata
        2. Decode base64 image to bytes
        3. Get/create broadcaster for camera
        4. Update frame in broadcaster
        5. Broadcaster automatically sends to all WebSocket viewers
    
    Returns:
        {
            "success": true,
            "viewers": 3,  # Number of active viewers
            "camera_id": "CAM1"
        }
    """
    try:
        # 1. Validate camera_id
        if not request.camera_id:
            raise HTTPException(status_code=400, detail="camera_id is required")
        
        # 2. Decode base64 image
        try:
            frame_bytes = base64.b64decode(request.frame_base64)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Invalid base64 data: {e}")
        
        # 3. Get or create broadcaster for this camera
        from services.detection_broadcaster import detection_broadcaster
        broadcaster = detection_broadcaster.get_broadcaster(request.camera_id)
        
        # 4. Update frame and broadcast to all viewers
        await broadcaster.update_frame(
            frame_bytes=frame_bytes,
            metadata=request.metadata
        )
        
        # 5. Return success with viewer count
        return {
            "success": True,
            "viewers": broadcaster.viewer_count,
            "camera_id": request.camera_id,
            "frame_size": len(frame_bytes),
            "timestamp": request.metadata.get('timestamp')
        }
    
    except HTTPException:
        raise
    
    except Exception as e:
        logger.error(f"Error broadcasting detection: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/broadcast-status")
async def get_broadcast_status():
    """
    Get status of all active broadcasters
    
    Returns:
        {
            "broadcasters": [
                {
                    "camera_id": "CAM1",
                    "viewers": 3,
                    "frame_count": 1234,
                    "last_update": 1641567890.123
                }
            ],
            "total_viewers": 5
        }
    """
    from services.detection_broadcaster import detection_broadcaster
    
    broadcasters_status = []
    total_viewers = 0
    
    for camera_id, broadcaster in detection_broadcaster.broadcasters.items():
        broadcasters_status.append({
            "camera_id": camera_id,
            "viewers": broadcaster.viewer_count,
            "frame_count": broadcaster.frame_count,
            "last_update": broadcaster.last_update
        })
        total_viewers += broadcaster.viewer_count
    
    return {
        "broadcasters": broadcasters_status,
        "total_viewers": total_viewers,
        "active_cameras": len(broadcasters_status)
    }
```

### 2. Request/Response Flow

**Request from Worker:**
```json
POST /api/broadcast-detection
Content-Type: application/json

{
  "camera_id": "CAM1",
  "frame_base64": "/9j/4AAQSkZJRg...(truncated)...==",
  "metadata": {
    "vehicle_count": 3,
    "occupied_spaces": 2,
    "total_spaces": 4,
    "timestamp": "2026-01-07T12:30:45.123456",
    "detections": [
      {
        "class": "car",
        "confidence": 0.87,
        "bbox": [100, 200, 150, 100],
        "track_id": 42,
        "center": [175, 250]
      },
      {
        "class": "car",
        "confidence": 0.92,
        "bbox": [300, 180, 140, 95],
        "track_id": 43,
        "center": [370, 227.5]
      },
      {
        "class": "motorcycle",
        "confidence": 0.78,
        "bbox": [450, 220, 80, 70],
        "track_id": 44,
        "center": [490, 255]
      }
    ],
    "space_occupancy": [
      {
        "space_id": "space_1",
        "space_name": "A1",
        "is_occupied": true,
        "bbox": {
          "x": 0.1,
          "y": 0.2,
          "width": 0.15,
          "height": 0.2
        }
      },
      {
        "space_id": "space_2",
        "space_name": "A2",
        "is_occupied": true,
        "bbox": {
          "x": 0.3,
          "y": 0.2,
          "width": 0.15,
          "height": 0.2
        }
      },
      {
        "space_id": "space_3",
        "space_name": "A3",
        "is_occupied": false,
        "bbox": {
          "x": 0.5,
          "y": 0.2,
          "width": 0.15,
          "height": 0.2
        }
      },
      {
        "space_id": "space_4",
        "space_name": "A4",
        "is_occupied": false,
        "bbox": {
          "x": 0.7,
          "y": 0.2,
          "width": 0.15,
          "height": 0.2
        }
      }
    ],
    "matched_detections": [
      {
        "detection": {
          "class": "car",
          "confidence": 0.87,
          "bbox": [100, 200, 150, 100],
          "track_id": 42
        },
        "space_id": "space_1"
      },
      {
        "detection": {
          "class": "car",
          "confidence": 0.92,
          "bbox": [300, 180, 140, 95],
          "track_id": 43
        },
        "space_id": "space_2"
      }
    ],
    "tracking_enabled": true
  }
}
```

**Response to Worker:**
```json
HTTP 200 OK

{
  "success": true,
  "viewers": 3,
  "camera_id": "CAM1",
  "frame_size": 45678,
  "timestamp": "2026-01-07T12:30:45.123456"
}
```

---

## Detection Broadcaster Service

### 1. Broadcaster Manager

**File:** `server/services/detection_broadcaster.py`

```python
import asyncio
import base64
import time
import logging
from typing import Dict, Set, Optional
from fastapi import WebSocket
from collections import defaultdict

logger = logging.getLogger(__name__)


class DetectionBroadcaster:
    """
    Manages broadcasting of detection frames to WebSocket viewers
    for a single camera
    """
    
    def __init__(self, camera_id: str):
        self.camera_id = camera_id
        self.current_frame: Optional[bytes] = None  # JPEG bytes
        self.metadata: Dict = {}
        self.viewers: Set[WebSocket] = set()
        self.last_update = time.time()
        self.frame_count = 0
        self._broadcast_lock = asyncio.Lock()
    
    async def update_frame(self, frame_bytes: bytes, metadata: Dict):
        """
        Update current frame and broadcast to all viewers
        
        Args:
            frame_bytes: JPEG encoded frame
            metadata: Detection statistics
        """
        async with self._broadcast_lock:
            self.current_frame = frame_bytes
            self.metadata = metadata
            self.last_update = time.time()
            self.frame_count += 1
            
            logger.debug(
                f"üì∏ Frame {self.frame_count} updated for {self.camera_id} "
                f"({len(frame_bytes)} bytes, {len(self.viewers)} viewers)"
            )
        
        # Broadcast to all viewers (outside lock)
        await self.broadcast_to_viewers()
    
    async def broadcast_to_viewers(self):
        """
        Send current frame to all connected WebSocket viewers
        
        Handles:
            - Encoding to base64
            - Sending to multiple viewers in parallel
            - Removing disconnected viewers
            - Timeout per viewer (500ms)
        """
        if not self.current_frame or not self.viewers:
            return
        
        broadcast_start = time.time()
        
        # Encode frame to base64 for WebSocket JSON
        frame_base64 = base64.b64encode(self.current_frame).decode('utf-8')
        
        # Prepare message
        message = {
            "type": "frame",
            "camera_id": self.camera_id,
            "frame": f"data:image/jpeg;base64,{frame_base64}",
            "metadata": self.metadata,
            "frame_count": self.frame_count,
            "timestamp": time.time()
        }
        
        # Send to all viewers in parallel
        send_tasks = []
        for viewer in self.viewers:
            send_tasks.append(self._send_to_viewer(viewer, message))
        
        # Wait for all sends to complete
        results = await asyncio.gather(*send_tasks, return_exceptions=True)
        
        # Remove disconnected viewers
        disconnected = []
        for viewer, result in zip(self.viewers, results):
            if isinstance(result, Exception):
                logger.warning(f"Viewer send failed: {result}")
                disconnected.append(viewer)
        
        for viewer in disconnected:
            self.viewers.discard(viewer)
            logger.info(f"üîå Removed disconnected viewer from {self.camera_id}")
        
        broadcast_time = (time.time() - broadcast_start) * 1000
        success_count = len(self.viewers) - len(disconnected)
        
        logger.debug(
            f"üì° Broadcast complete: {success_count}/{len(self.viewers)} viewers "
            f"in {broadcast_time:.1f}ms"
        )
    
    async def _send_to_viewer(self, viewer: WebSocket, message: dict):
        """
        Send message to single viewer with timeout
        
        Args:
            viewer: WebSocket connection
            message: JSON message to send
        
        Raises:
            Exception if send fails or times out
        """
        try:
            await asyncio.wait_for(
                viewer.send_json(message),
                timeout=0.5  # 500ms timeout per viewer
            )
        except asyncio.TimeoutError:
            raise Exception("Viewer send timeout (500ms)")
        except Exception as e:
            raise Exception(f"Viewer send error: {e}")
    
    async def add_viewer(self, websocket: WebSocket):
        """
        Add new viewer to broadcaster
        
        Args:
            websocket: WebSocket connection
        
        Flow:
            1. Accept WebSocket connection
            2. Add to viewers set
            3. Send current frame immediately (if available)
        """
        await websocket.accept()
        self.viewers.add(websocket)
        
        logger.info(
            f"‚úÖ Viewer connected to {self.camera_id}: "
            f"{len(self.viewers)} total"
        )
        
        # Send current frame immediately if available
        if self.current_frame:
            await self.send_frame_to_viewer(websocket)
    
    async def send_frame_to_viewer(self, websocket: WebSocket):
        """Send current frame to specific viewer"""
        if not self.current_frame:
            return
        
        try:
            frame_base64 = base64.b64encode(self.current_frame).decode('utf-8')
            
            message = {
                "type": "frame",
                "camera_id": self.camera_id,
                "frame": f"data:image/jpeg;base64,{frame_base64}",
                "metadata": self.metadata,
                "frame_count": self.frame_count,
                "timestamp": time.time()
            }
            
            await websocket.send_json(message)
            logger.debug(f"üì§ Sent current frame to new viewer")
        
        except Exception as e:
            logger.error(f"Failed to send frame to new viewer: {e}")
    
    def remove_viewer(self, websocket: WebSocket):
        """
        Remove viewer from broadcaster
        
        Args:
            websocket: WebSocket connection to remove
        """
        self.viewers.discard(websocket)
        logger.info(
            f"üîå Viewer disconnected from {self.camera_id}: "
            f"{len(self.viewers)} remaining"
        )
    
    @property
    def viewer_count(self) -> int:
        """Get number of active viewers"""
        return len(self.viewers)


class DetectionBroadcasterManager:
    """
    Manages multiple DetectionBroadcasters (one per camera)
    
    Singleton pattern for global access
    """
    
    def __init__(self):
        self.broadcasters: Dict[str, DetectionBroadcaster] = {}
        self._lock = asyncio.Lock()
    
    def get_broadcaster(self, camera_id: str) -> DetectionBroadcaster:
        """
        Get or create broadcaster for camera
        
        Args:
            camera_id: Camera identifier
        
        Returns:
            DetectionBroadcaster instance
        """
        if camera_id not in self.broadcasters:
            self.broadcasters[camera_id] = DetectionBroadcaster(camera_id)
            logger.info(f"üìπ Created broadcaster for camera {camera_id}")
        
        return self.broadcasters[camera_id]
    
    def cleanup_inactive(self, max_age: float = 300):
        """
        Remove broadcasters with no viewers and no recent updates
        
        Args:
            max_age: Maximum age in seconds (default: 5 minutes)
        """
        current_time = time.time()
        to_remove = []
        
        for camera_id, broadcaster in self.broadcasters.items():
            age = current_time - broadcaster.last_update
            
            if broadcaster.viewer_count == 0 and age > max_age:
                to_remove.append(camera_id)
        
        for camera_id in to_remove:
            del self.broadcasters[camera_id]
            logger.info(f"üóëÔ∏è Removed inactive broadcaster: {camera_id}")


# Global singleton instance
detection_broadcaster = DetectionBroadcasterManager()
```

### 2. WebSocket Endpoint

**File:** `server/routers/worker_detection_stream.py`

```python
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Query
import asyncio
import logging

router = APIRouter(prefix="/ws/viewer", tags=["Detection Stream"])
logger = logging.getLogger(__name__)


@router.websocket("/detection")
async def viewer_websocket(
    websocket: WebSocket,
    camera_id: str = Query(..., description="Camera ID to view")
):
    """
    WebSocket endpoint for viewers to receive detection streams
    
    Protocol:
        - Client connects with camera_id query parameter
        - Server adds viewer to broadcaster
        - Server sends frame updates automatically
        - Client can send "ping" to keep connection alive
        - Client disconnects ‚Üí Server removes from broadcaster
    
    Message Types (Server ‚Üí Client):
        1. Frame Update:
           {
               "type": "frame",
               "camera_id": "CAM1",
               "frame": "data:image/jpeg;base64,...",
               "metadata": {...},
               "frame_count": 1234,
               "timestamp": 1641567890.123
           }
        
        2. Keepalive:
           "keepalive"
    
    Message Types (Client ‚Üí Server):
        1. Ping: "ping"
        2. Pong: "pong"
    """
    from services.detection_broadcaster import detection_broadcaster
    
    broadcaster = detection_broadcaster.get_broadcaster(camera_id)
    
    try:
        # Add viewer to broadcaster
        await broadcaster.add_viewer(websocket)
        
        logger.info(f"üé• Viewer connected to camera {camera_id}")
        
        # Keep connection alive
        while True:
            try:
                # Wait for client messages (ping/pong for keepalive)
                data = await asyncio.wait_for(
                    websocket.receive_text(),
                    timeout=30.0  # 30 second timeout
                )
                
                # Handle client messages
                if data == "ping":
                    await websocket.send_text("pong")
                    logger.debug(f"üèì Ping/pong with viewer")
            
            except asyncio.TimeoutError:
                # No message received in 30s - send keepalive
                try:
                    await websocket.send_text("keepalive")
                    logger.debug(f"üíì Sent keepalive to viewer")
                except Exception as e:
                    logger.warning(f"Keepalive failed: {e}")
                    break
    
    except WebSocketDisconnect:
        logger.info(f"üîå Viewer disconnected from camera {camera_id}")
    
    except Exception as e:
        logger.error(f"‚ùå WebSocket error for camera {camera_id}: {e}")
    
    finally:
        # Remove viewer from broadcaster
        broadcaster.remove_viewer(websocket)
        logger.info(
            f"üëã Viewer removed from camera {camera_id} "
            f"({broadcaster.viewer_count} remaining)"
        )
```

---

## Frontend Viewer Layer

### 1. React Component

**File:** `frontend/src/pages/DetectionViewerPage.tsx`

```typescript
import React, { useState, useEffect, useRef } from 'react';

interface DetectionMetadata {
  vehicle_count: number;
  occupied_spaces: number;
  total_spaces: number;
  timestamp: string;
  track_ids?: number[];
}

interface FrameMessage {
  type: string;
  camera_id: string;
  frame: string;  // Base64 data URL
  metadata: DetectionMetadata;
  frame_count: number;
  timestamp: number;
}

export function DetectionViewerPage() {
  const [cameras, setCameras] = useState<any[]>([]);
  const [selectedCamera, setSelectedCamera] = useState<string>('');
  const [frameData, setFrameData] = useState<string>('');
  const [metadata, setMetadata] = useState<DetectionMetadata | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [frameCount, setFrameCount] = useState(0);
  const [fps, setFps] = useState(0);
  
  const wsRef = useRef<WebSocket | null>(null);
  const fpsCounterRef = useRef({ count: 0, lastTime: Date.now() });
  
  // Load cameras on mount
  useEffect(() => {
    loadCameras();
  }, []);
  
  // Connect to WebSocket when camera selected
  useEffect(() => {
    if (!selectedCamera) return;
    
    connectWebSocket(selectedCamera);
    
    return () => {
      disconnectWebSocket();
    };
  }, [selectedCamera]);
  
  const loadCameras = async () => {
    try {
      const response = await fetch('http://localhost:8069/api/cameras');
      const data = await response.json();
      setCameras(data.cameras || []);
    } catch (error) {
      console.error('Failed to load cameras:', error);
    }
  };
  
  const connectWebSocket = (cameraId: string) => {
    const wsUrl = `ws://localhost:8069/ws/viewer/detection?camera_id=${cameraId}`;
    const ws = new WebSocket(wsUrl);
    
    ws.onopen = () => {
      console.log('‚úÖ WebSocket connected to', cameraId);
      setIsConnected(true);
    };
    
    ws.onmessage = (event) => {
      try {
        // Handle text messages (keepalive, pong)
        if (typeof event.data === 'string' && event.data !== 'keepalive') {
          const message: FrameMessage = JSON.parse(event.data);
          
          if (message.type === 'frame') {
            // Update frame
            setFrameData(message.frame);
            setMetadata(message.metadata);
            setFrameCount(message.frame_count);
            
            // Calculate FPS
            updateFpsCounter();
          }
        }
      } catch (error) {
        console.error('Error parsing WebSocket message:', error);
      }
    };
    
    ws.onerror = (error) => {
      console.error('‚ùå WebSocket error:', error);
      setIsConnected(false);
    };
    
    ws.onclose = () => {
      console.log('üîå WebSocket closed');
      setIsConnected(false);
    };
    
    wsRef.current = ws;
    
    // Send ping every 10 seconds to keep connection alive
    const pingInterval = setInterval(() => {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send('ping');
      }
    }, 10000);
    
    // Cleanup
    return () => {
      clearInterval(pingInterval);
    };
  };
  
  const disconnectWebSocket = () => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
    setIsConnected(false);
    setFrameData('');
    setMetadata(null);
    setFrameCount(0);
    setFps(0);
  };
  
  const updateFpsCounter = () => {
    const counter = fpsCounterRef.current;
    counter.count++;
    
    const now = Date.now();
    const elapsed = now - counter.lastTime;
    
    // Update FPS every second
    if (elapsed >= 1000) {
      const currentFps = (counter.count / elapsed) * 1000;
      setFps(Math.round(currentFps * 10) / 10);
      
      counter.count = 0;
      counter.lastTime = now;
    }
  };
  
  return (
    <div className="min-h-screen bg-gray-100 p-6">
      <div className="max-w-7xl mx-auto">
        {/* Header */}
        <div className="bg-white rounded-lg shadow p-6 mb-6">
          <h1 className="text-3xl font-bold mb-4">üé• Detection Viewer</h1>
          
          {/* Camera Selector */}
          <div className="flex items-center gap-4">
            <label className="font-medium">Select Camera:</label>
            <select
              value={selectedCamera}
              onChange={(e) => setSelectedCamera(e.target.value)}
              className="px-4 py-2 border rounded-lg"
            >
              <option value="">-- Select Camera --</option>
              {cameras.map(cam => (
                <option key={cam.id} value={cam.id}>
                  {cam.name} ({cam.id})
                </option>
              ))}
            </select>
            
            {/* Connection Status */}
            <div className={`px-3 py-1 rounded-full text-sm font-medium ${
              isConnected 
                ? 'bg-green-100 text-green-800' 
                : 'bg-red-100 text-red-800'
            }`}>
              {isConnected ? 'üü¢ Connected' : 'üî¥ Disconnected'}
            </div>
          </div>
        </div>
        
        {/* Video Stream */}
        {selectedCamera && (
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
            {/* Main Video */}
            <div className="lg:col-span-2 bg-white rounded-lg shadow p-4">
              <h2 className="text-xl font-bold mb-4">Live Stream</h2>
              
              {frameData ? (
                <img
                  src={frameData}
                  alt="Detection Stream"
                  className="w-full rounded-lg"
                />
              ) : (
                <div className="w-full h-96 bg-gray-200 rounded-lg flex items-center justify-center">
                  <p className="text-gray-500">Waiting for frames...</p>
                </div>
              )}
              
              {/* Stream Stats */}
              <div className="mt-4 flex items-center gap-6 text-sm text-gray-600">
                <div>Frame: {frameCount}</div>
                <div>FPS: {fps}</div>
                {metadata && (
                  <div>Latency: {calculateLatency(metadata.timestamp)}ms</div>
                )}
              </div>
            </div>
            
            {/* Statistics Panel */}
            <div className="bg-white rounded-lg shadow p-4">
              <h2 className="text-xl font-bold mb-4">üìä Statistics</h2>
              
              {metadata ? (
                <div className="space-y-4">
                  {/* Vehicle Count */}
                  <div className="bg-blue-50 rounded-lg p-4">
                    <div className="text-sm text-gray-600">Vehicles</div>
                    <div className="text-3xl font-bold text-blue-600">
                      {metadata.vehicle_count}
                    </div>
                  </div>
                  
                  {/* Parking Occupancy */}
                  <div className="bg-green-50 rounded-lg p-4">
                    <div className="text-sm text-gray-600">Parking</div>
                    <div className="text-xl font-bold text-green-600">
                      {metadata.occupied_spaces} / {metadata.total_spaces}
                    </div>
                    <div className="text-sm text-gray-600 mt-1">
                      {metadata.total_spaces - metadata.occupied_spaces} available
                    </div>
                  </div>
                  
                  {/* Occupancy Bar */}
                  <div>
                    <div className="flex justify-between text-sm mb-1">
                      <span>Occupancy</span>
                      <span>{calculateOccupancy(metadata)}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div
                        className="bg-blue-600 h-2 rounded-full transition-all"
                        style={{ width: `${calculateOccupancy(metadata)}%` }}
                      />
                    </div>
                  </div>
                  
                  {/* Track IDs */}
                  {metadata.track_ids && metadata.track_ids.length > 0 && (
                    <div className="bg-purple-50 rounded-lg p-4">
                      <div className="text-sm text-gray-600 mb-2">
                        Active Track IDs
                      </div>
                      <div className="flex flex-wrap gap-2">
                        {metadata.track_ids.map(id => (
                          <span
                            key={id}
                            className="px-2 py-1 bg-purple-200 text-purple-800 rounded text-sm font-mono"
                          >
                            #{id}
                          </span>
                        ))}
                      </div>
                    </div>
                  )}
                  
                  {/* Timestamp */}
                  <div className="text-xs text-gray-500">
                    Last update: {new Date(metadata.timestamp).toLocaleTimeString()}
                  </div>
                </div>
              ) : (
                <div className="text-gray-500">No data available</div>
              )}
            </div>
          </div>
        )}
      </div>
    </div>
  );
}

// Helper functions
function calculateOccupancy(metadata: DetectionMetadata): number {
  if (metadata.total_spaces === 0) return 0;
  return Math.round((metadata.occupied_spaces / metadata.total_spaces) * 100);
}

function calculateLatency(timestamp: string): number {
  const frameTime = new Date(timestamp).getTime();
  const now = Date.now();
  return now - frameTime;
}
```

---

## Message Formats

### 1. Worker ‚Üí FastAPI

**HTTP POST Request:**
```json
{
  "camera_id": "CAM1",
  "frame_base64": "/9j/4AAQSkZJRgABAQAAAQ...(JPEG base64)...==",
  "metadata": {
    "vehicle_count": 3,
    "occupied_spaces": 2,
    "total_spaces": 4,
    "timestamp": "2026-01-07T12:30:45.123456",
    "track_ids": [42, 43, 44]
  }
}
```

### 2. FastAPI ‚Üí Frontend (WebSocket)

**Frame Message:**
```json
{
  "type": "frame",
  "camera_id": "CAM1",
  "frame": "data:image/jpeg;base64,/9j/4AAQSkZJRg...",
  "metadata": {
    "vehicle_count": 3,
    "occupied_spaces": 2,
    "total_spaces": 4,
    "timestamp": "2026-01-07T12:30:45.123456",
    "track_ids": [42, 43, 44]
  },
  "frame_count": 1234,
  "timestamp": 1641567890.123
}
```

**Keepalive Message:**
```
"keepalive"
```

### 3. Frontend ‚Üí FastAPI (WebSocket)

**Ping Message:**
```
"ping"
```

**Pong Response:**
```
"pong"
```

---

## Performance Optimization

### 1. Frame Size Optimization

**JPEG Quality Settings:**
```python
# Worker encoding
cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
# Quality 85 = Good balance (45-60 KB per frame)
```

**Frame Size Comparison:**
- Quality 95: ~120 KB (overkill for streaming)
- Quality 85: ~50 KB (optimal)
- Quality 70: ~30 KB (noticeable quality loss)

### 2. Broadcasting Optimization

**Parallel Sends:**
```python
# Send to all viewers in parallel (not sequential)
send_tasks = [self._send_to_viewer(v, msg) for v in viewers]
await asyncio.gather(*send_tasks, return_exceptions=True)
```

**Timeouts:**
```python
# Timeout per viewer: 500ms
await asyncio.wait_for(viewer.send_json(message), timeout=0.5)
```

### 3. Connection Management

**Automatic Cleanup:**
- Remove viewers on WebSocket disconnect
- Remove viewers on send timeout
- Cleanup inactive broadcasters (5min no activity)

**Keepalive Protocol:**
- Client sends ping every 10s
- Server sends keepalive if no message in 30s
- Prevents firewall/proxy connection drops

---

## Error Handling

### 1. Worker Level

```python
try:
    await self.broadcast_frame_to_viewers(...)
except asyncio.TimeoutError:
    logger.warning("Broadcast timeout (> 5s)")
    # Continue processing (don't crash worker)
except aiohttp.ClientError:
    logger.error("Network error, FastAPI unreachable")
    # Continue processing (FastAPI might be restarting)
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    # Continue processing (log for debugging)
```

### 2. FastAPI Level

```python
try:
    frame_bytes = base64.b64decode(request.frame_base64)
except Exception as e:
    raise HTTPException(400, f"Invalid base64: {e}")

try:
    await broadcaster.update_frame(...)
except Exception as e:
    raise HTTPException(500, f"Broadcast failed: {e}")
```

### 3. Frontend Level

```typescript
ws.onerror = (error) => {
  console.error('WebSocket error:', error);
  setIsConnected(false);
  
  // Auto-reconnect after 3 seconds
  setTimeout(() => {
    connectWebSocket(selectedCamera);
  }, 3000);
};
```

---

## Summary

### Key Features
1. ‚úÖ **Real-time Streaming** - Worker ‚Üí FastAPI ‚Üí Viewers (< 200ms latency)
2. ‚úÖ **Multiple Viewers** - Broadcast to unlimited viewers per camera
3. ‚úÖ **Automatic Cleanup** - Remove disconnected viewers, inactive broadcasters
4. ‚úÖ **Keepalive Protocol** - Prevent connection drops
5. ‚úÖ **Error Resilient** - Continue operation on failures
6. ‚úÖ **Optimized Performance** - Parallel sends, timeouts, frame compression

### Latency Breakdown
```
Total E2E Latency: ~150-200ms
‚îú‚îÄ Worker encode: 10ms
‚îú‚îÄ HTTP POST: 5ms
‚îú‚îÄ FastAPI process: 5ms
‚îú‚îÄ WebSocket send: 10ms
‚îî‚îÄ Frontend render: 120-150ms (browser)
```

### Scalability
- **Cameras:** Unlimited (limited by worker CPU/GPU)
- **Viewers per Camera:** Unlimited (limited by network bandwidth)
- **Concurrent Connections:** 1000+ (with proper server config)

---

**Last Updated:** January 7, 2026
**Version:** 1.0
**Author:** Smart Parking System Team
