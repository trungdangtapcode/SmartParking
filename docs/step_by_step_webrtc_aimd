# üöÄ H∆∞·ªõng D·∫´n Step-by-Step: Smart Parking v·ªõi WebRTC + AI

## üìå T·ªïng Quan Solution

### Ki·∫øn tr√∫c:
```
Camera (WebRTC) 
    ‚Üì
Browser (Live Stream)
    ‚Üì
AI Model (Roboflow Custom Model) - Detect qua API
    ‚Üì
Detect parking spaces real-time
    ‚Üì
Firestore (Ch·ªâ l∆∞u k·∫øt qu·∫£ detection)
```

### ∆Øu ƒëi·ªÉm:
- ‚úÖ **100% MI·ªÑN PH√ç** - Kh√¥ng c·∫ßn Storage, kh√¥ng c·∫ßn Cloud Functions
- ‚úÖ **Real-time** - Detect ngay l·∫≠p t·ª©c
- ‚úÖ **Privacy** - Video kh√¥ng r·ªùi kh·ªèi browser
- ‚úÖ **ƒê∆°n gi·∫£n** - Ch·ªâ c·∫ßn Firestore (kh√¥ng c·∫ßn Firebase Storage)

---

## üìã M·ª§C L·ª§C

- [B∆∞·ªõc 0: Chu·∫©n B·ªã](#b∆∞·ªõc-0-chu·∫©n-b·ªã)
- [B∆∞·ªõc 1: Setup Project](#b∆∞·ªõc-1-setup-project)
- [B∆∞·ªõc 2: Setup Firestore (Ch·ªâ Database)](#b∆∞·ªõc-2-setup-firestore)
- [B∆∞·ªõc 3: Setup Roboflow AI Model](#b∆∞·ªõc-3-setup-roboflow-ai-model)
- [B∆∞·ªõc 4: Build WebRTC Live Camera](#b∆∞·ªõc-4-build-webrtc-live-camera)
- [B∆∞·ªõc 5: Integrate AI Detection](#b∆∞·ªõc-5-integrate-ai-detection)
- [B∆∞·ªõc 6: Save Results to Firestore](#b∆∞·ªõc-6-save-results-to-firestore)
- [B∆∞·ªõc 7: Build Dashboard](#b∆∞·ªõc-7-build-dashboard)
- [B∆∞·ªõc 8: Testing & Polish](#b∆∞·ªõc-8-testing--polish)

---

## B∆∞·ªõc 0: Chu·∫©n B·ªã

### ‚úÖ Checklist

```bash
# Check Node.js (c·∫ßn >= 18.0.0)
node --version

# Check npm
npm --version
```

### üì¶ Tools C·∫ßn C√†i

1. **Node.js** v18+: https://nodejs.org/
2. **VS Code**: https://code.visualstudio.com/
3. **Git**: https://git-scm.com/

### üîß VS Code Extensions (Khuy·∫øn ngh·ªã)

- ESLint
- Prettier  
- Tailwind CSS IntelliSense
- ES7+ React/Redux snippets

---

## B∆∞·ªõc 1: Setup Project

### 1.1. V√†o Folder Frontend

```bash
cd D:\SmartParking\frontend
```

### 1.2. Install Dependencies

```bash
# Core dependencies
npm install react-router-dom

# Tailwind CSS
npm install -D tailwindcss postcss autoprefixer @tailwindcss/postcss
npm install

# Firebase (CH·ªà Firestore, KH√îNG c·∫ßn Storage)
npm install firebase

# Roboflow AI Detection (Custom model cho parking detection)
npm install axios

# Chart.js (bi·ªÉu ƒë·ªì)
npm install chart.js react-chartjs-2

# Utilities
npm install date-fns
```

### 1.3. T·∫°o C·∫•u Tr√∫c Folders

```bash
cd src
mkdir components pages services hooks types config
mkdir services/ai
```

**K·∫øt qu·∫£:**
```
src/
‚îú‚îÄ‚îÄ components/     # UI components
‚îú‚îÄ‚îÄ pages/          # Page components
‚îú‚îÄ‚îÄ services/       # Services
‚îÇ   ‚îî‚îÄ‚îÄ ai/         # AI detection service
‚îú‚îÄ‚îÄ hooks/          # Custom React hooks
‚îú‚îÄ‚îÄ types/          # TypeScript types
‚îî‚îÄ‚îÄ config/         # Firebase config
```

### 1.4. Test Run

```bash
npm run dev
```

M·ªü http://localhost:5173 - Ph·∫£i th·∫•y trang Vite m·∫∑c ƒë·ªãnh.

### ‚úÖ Checkpoint 1
- [Y] Project ch·∫°y ƒë∆∞·ª£c
- [Y] Tailwind CSS ho·∫°t ƒë·ªông
- [Y] Kh√¥ng c√≥ l·ªói

---

## B∆∞·ªõc 2: Setup Firestore (Ch·ªâ Database)

> **L∆ØU √ù**: Ch√∫ng ta CH·ªà d√πng Firestore (database), KH√îNG d√πng Storage!

### 2.1. T·∫°o Firebase Project

1. V√†o https://console.firebase.google.com/
2. Click **"Add project"**
3. Nh·∫≠p t√™n: `smart-parking-webrtc`
4. Disable Google Analytics
5. Click **"Create project"**

### 2.2. Enable Firestore

1. Sidebar ‚Üí Click **"Firestore Database"**
2. Click **"Create database"**
3. Ch·ªçn **"Start in test mode"** (ƒë·ªÉ dev d·ªÖ)
4. Location: `asia-southeast1` (Singapore)
5. Click **"Enable"**

### 2.3. L·∫•y Firebase Config

1. Click ‚öôÔ∏è ‚Üí **"Project settings"**
2. Scroll xu·ªëng **"Your apps"**
3. Click icon **Web** (`</>`)
4. Nickname: `smart-parking-web`
5. Click **"Register app"**
6. Copy config

### 2.4. T·∫°o File Config

**File: `.env.local`** (T·∫†O M·ªöI ·ªü root frontend)

```env
VITE_FIREBASE_API_KEY=AIzaSy...
VITE_FIREBASE_AUTH_DOMAIN=smart-parking-webrtc.firebaseapp.com
VITE_FIREBASE_PROJECT_ID=smart-parking-webrtc
VITE_FIREBASE_STORAGE_BUCKET=smart-parking-webrtc.appspot.com
VITE_FIREBASE_MESSAGING_SENDER_ID=123456789
VITE_FIREBASE_APP_ID=1:123456789:web:abc123
```

**File: `src/config/firebase.ts`** (T·∫†O M·ªöI)

```typescript
import { initializeApp } from 'firebase/app';
import { getFirestore } from 'firebase/firestore';

const firebaseConfig = {
  apiKey: import.meta.env.VITE_FIREBASE_API_KEY,
  authDomain: import.meta.env.VITE_FIREBASE_AUTH_DOMAIN,
  projectId: import.meta.env.VITE_FIREBASE_PROJECT_ID,
  storageBucket: import.meta.env.VITE_FIREBASE_STORAGE_BUCKET,
  messagingSenderId: import.meta.env.VITE_FIREBASE_MESSAGING_SENDER_ID,
  appId: import.meta.env.VITE_FIREBASE_APP_ID,
};

// Initialize Firebase
const app = initializeApp(firebaseConfig);

// Export ONLY Firestore (kh√¥ng c·∫ßn Storage)
export const db = getFirestore(app);

export default app;
```

### 2.5. Test Connection

**File: `src/App.tsx`** (TEST)

```typescript
import { useEffect } from 'react';
import { collection, getDocs } from 'firebase/firestore';
import { db } from './config/firebase';

function App() {
  useEffect(() => {
    // Test Firestore connection
    const testFirestore = async () => {
      try {
        const querySnapshot = await getDocs(collection(db, 'test'));
        console.log('‚úÖ Firestore connected! Documents:', querySnapshot.size);
      } catch (error) {
        console.error('‚ùå Firestore error:', error);
      }
    };
    
    testFirestore();
  }, []);

  return (
    <div className="p-8">
      <h1 className="text-3xl font-bold">Smart Parking</h1>
      <p>Check console for Firestore connection status</p>
    </div>
  );
}

export default App;
```

**Ch·∫°y:**
```bash
npm run dev
```

**Ki·ªÉm tra Console:** Ph·∫£i th·∫•y "‚úÖ Firestore connected!"

### ‚úÖ Checkpoint 2
- [Y] Firebase project ƒë√£ t·∫°o
- [Y] Firestore ƒë√£ enable
- [Y] `.env.local` ƒë√£ c√≥ config
- [Y] Console log "Firestore connected!"

---

## B∆∞·ªõc 3: Setup Roboflow AI Model

### 3.1. Gi·∫£i Th√≠ch Roboflow

**Roboflow l√† g√¨?**
- Platform ƒë·ªÉ train **custom AI models**
- Model ƒë√£ ƒë∆∞·ª£c train ri√™ng cho **parking detection**
- Ch·∫°y qua API, r·∫•t nhanh v√† ch√≠nh x√°c

**Model deteksiparkirkosong:**
- Custom model train ƒë·ªÉ detect ch·ªó ƒë·ªó xe
- Classes: `available`, `occupied`, v.v.
- ƒê·ªô ch√≠nh x√°c cao h∆°n COCO-SSD cho parking
- Link: https://universe.roboflow.com/skripsijeremy/deteksiparkirkosong/model/6

### 3.2. L·∫•y Roboflow API Key

1. V√†o https://roboflow.com/ v√† **Sign Up** (mi·ªÖn ph√≠)
2. V√†o **Workspace Settings** (icon ‚öôÔ∏è)
3. Tab **Roboflow API**
4. Copy **API Key** (d·∫°ng: `abc123xyz...`)

### 3.3. C·∫•u H√¨nh API Key

**File: `env.local`** (UPDATE - th√™m v√†o cu·ªëi file)

```env
# Roboflow API Configuration
VITE_ROBOFLOW_API_KEY=YOUR_API_KEY_HERE
VITE_ROBOFLOW_MODEL_ID=deteksiparkirkosong
VITE_ROBOFLOW_MODEL_VERSION=6
```

> **L∆ØU √ù**: Thay `YOUR_API_KEY_HERE` b·∫±ng API key th·∫≠t t·ª´ Roboflow!

### 3.4. T·∫°o AI Detection Service

**File: `src/services/ai/aiDetection.ts`** (T·∫†O M·ªöI)

```typescript
import axios from 'axios';

/**
 * Detection Result t·ª´ Roboflow AI
 */
export interface Detection {
  class: string;      // 'available', 'occupied', etc.
  score: number;      // Confidence 0-1
  bbox: [number, number, number, number]; // [x, y, width, height]
}

/**
 * Roboflow API Response
 */
interface RoboflowPrediction {
  x: number;
  y: number;
  width: number;
  height: number;
  confidence: number;
  class: string;
}

/**
 * AI Detection Service using Roboflow
 */
class AIDetectionService {
  private apiKey: string;
  private modelId: string;
  private modelVersion: string;
  private apiUrl: string;
  private modelLoaded: boolean = false;
  
  constructor() {
    this.apiKey = import.meta.env.VITE_ROBOFLOW_API_KEY || '';
    this.modelId = import.meta.env.VITE_ROBOFLOW_MODEL_ID || 'deteksiparkirkosong';
    this.modelVersion = import.meta.env.VITE_ROBOFLOW_MODEL_VERSION || '6';
    this.apiUrl = `https://detect.roboflow.com/${this.modelId}/${this.modelVersion}`;
  }
  
  /**
   * Load AI model (check credentials)
   */
  async loadModel(): Promise<void> {
    if (this.modelLoaded) return;
    
    if (!this.apiKey || this.apiKey === 'YOUR_ROBOFLOW_API_KEY_HERE') {
      throw new Error('‚ùå Roboflow API Key not configured!');
    }
    
    console.log('ü§ñ Roboflow Model Ready!');
    console.log(`üì¶ Model: ${this.modelId} v${this.modelVersion}`);
    this.modelLoaded = true;
  }
  
  /**
   * Convert video/image to base64
   */
  private toBase64(source: HTMLVideoElement | HTMLImageElement): string {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d')!;
    
    const width = source instanceof HTMLVideoElement 
      ? source.videoWidth 
      : source.naturalWidth;
    const height = source instanceof HTMLVideoElement 
      ? source.videoHeight 
      : source.naturalHeight;
    
    canvas.width = width;
    canvas.height = height;
    ctx.drawImage(source, 0, 0, width, height);
    
    return canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
  }
  
  /**
   * Detect parking spaces trong image/video frame
   */
  async detectVehicles(
    source: HTMLVideoElement | HTMLImageElement
  ): Promise<Detection[]> {
    if (!this.modelLoaded) {
      throw new Error('Model not loaded!');
    }
    
    try {
      const base64Image = this.toBase64(source);
      
      const response = await axios.post(
        this.apiUrl,
        base64Image,
        {
          params: {
            api_key: this.apiKey,
            confidence: 40,
            overlap: 30
          },
          headers: {
            'Content-Type': 'application/x-www-form-urlencoded'
          },
          timeout: 5000
        }
      );
      
      const predictions: RoboflowPrediction[] = response.data.predictions || [];
      
      return predictions.map(p => ({
        class: p.class,
        score: p.confidence,
        bbox: [
          p.x - p.width / 2,
          p.y - p.height / 2,
          p.width,
          p.height
        ] as [number, number, number, number]
      }));
      
    } catch (error) {
      console.error('‚ùå Detection error:', error);
      return [];
    }
  }
}

// Export singleton instance
export const aiDetection = new AIDetectionService();
```

### 3.5. Test AI Detection

**File: `src/App.tsx`** (UPDATE)

```typescript
import { useEffect, useState } from 'react';
import { aiDetection } from './services/ai/aiDetection';

function App() {
  const [modelLoaded, setModelLoaded] = useState(false);
  
  useEffect(() => {
    // Load AI model khi app kh·ªüi ƒë·ªông
    const loadAI = async () => {
      try {
        await aiDetection.loadModel();
        setModelLoaded(true);
      } catch (error) {
        console.error('‚ùå Failed to load AI:', error);
      }
    };
    
    loadAI();
  }, []);

  return (
    <div className="p-8">
      <h1 className="text-3xl font-bold mb-4">Smart Parking</h1>
      
      {modelLoaded ? (
        <div className="text-green-600">
          ‚úÖ AI Model loaded and ready!
        </div>
      ) : (
        <div className="text-yellow-600">
          ‚è≥ Loading AI model...
        </div>
      )}
    </div>
  );
}

export default App;
```

**Ch·∫°y:**
```bash
npm run dev
```

**Ph·∫£i th·∫•y:**
1. "‚è≥ Loading AI model..." (1-2 gi√¢y)
2. Sau ƒë√≥ "‚úÖ AI Model loaded and ready!"
3. Console log: "ü§ñ Roboflow Model Ready!"

> **L∆ØU √ù**: N·∫øu th·∫•y l·ªói "API Key not configured", h√£y check l·∫°i file `env.local`!

### ‚úÖ Checkpoint 3
- [Y] Roboflow API key ƒë√£ config
- [Y] axios installed
- [Y] Console log "Roboflow Model Ready!"

---

## B∆∞·ªõc 4: Build WebRTC Live Camera

### 4.1. Gi·∫£i Th√≠ch WebRTC

**WebRTC l√† g√¨?**
- **Web Real-Time Communication**
- Built-in trong browsers
- L·∫•y camera/mic tr·ª±c ti·∫øp
- **MI·ªÑN PH√ç**, kh√¥ng c·∫ßn server

**`getUserMedia()` l√† g√¨?**
- API ƒë·ªÉ xin quy·ªÅn truy c·∫≠p camera
- Tr·∫£ v·ªÅ video stream
- Stream n√†y hi·ªÉn th·ªã real-time

### 4.2. T·∫°o Live Camera Component

**File: `src/components/LiveCamera.tsx`** (T·∫†O M·ªöI)

```typescript
import { useEffect, useRef, useState } from 'react';

interface LiveCameraProps {
  onStreamReady?: (stream: MediaStream) => void;
}

export function LiveCamera({ onStreamReady }: LiveCameraProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [isStreaming, setIsStreaming] = useState(false);
  const [error, setError] = useState<string>('');
  
  useEffect(() => {
    let stream: MediaStream | null = null;
    
    const startCamera = async () => {
      try {
        // Xin quy·ªÅn truy c·∫≠p camera
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 1280 },
            height: { ideal: 720 },
            frameRate: { ideal: 30 }
          },
          audio: false // Kh√¥ng c·∫ßn audio
        });
        
        // Hi·ªÉn th·ªã video stream
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          setIsStreaming(true);
          
          // Notify parent component
          if (onStreamReady) {
            onStreamReady(stream);
          }
        }
      } catch (err) {
        console.error('Camera error:', err);
        setError('Kh√¥ng th·ªÉ truy c·∫≠p camera. Vui l√≤ng cho ph√©p quy·ªÅn camera.');
      }
    };
    
    startCamera();
    
    // Cleanup: T·∫Øt camera khi component unmount
    return () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, [onStreamReady]);
  
  return (
    <div className="relative">
      {error && (
        <div className="text-red-600 mb-4 p-4 bg-red-50 rounded">
          ‚ö†Ô∏è {error}
        </div>
      )}
      
      <div className="relative">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="w-full max-w-4xl rounded-lg shadow-lg border-4 border-blue-500"
        />
        
        {isStreaming && (
          <div className="absolute top-4 right-4 bg-red-600 text-white px-3 py-1 rounded-full flex items-center gap-2">
            <span className="w-2 h-2 bg-white rounded-full animate-pulse"></span>
            LIVE
          </div>
        )}
      </div>
    </div>
  );
}
```

### 4.3. Test Live Camera

**File: `src/pages/LiveViewPage.tsx`** (T·∫†O M·ªöI)

```typescript
import { LiveCamera } from '../components/LiveCamera';

export function LiveViewPage() {
  return (
    <div className="p-8">
      <h1 className="text-3xl font-bold mb-4">
        üìπ Live Parking Camera
      </h1>
      
      <div className="mb-4 p-4 bg-blue-50 rounded">
        <p className="text-gray-700">
          ‚ÑπÔ∏è Tr√¨nh duy·ªát s·∫Ω h·ªèi quy·ªÅn truy c·∫≠p camera. Nh·∫•n <strong>"Allow"</strong>.
        </p>
      </div>
      
      <LiveCamera 
        onStreamReady={(stream) => {
          console.log('‚úÖ Camera stream ready:', stream);
        }}
      />
    </div>
  );
}
```

**File: `src/App.tsx`** (UPDATE ƒë·ªÉ test)

```typescript
import { LiveViewPage } from './pages/LiveViewPage';

function App() {
  return <LiveViewPage />;
}

export default App;
```

**Ch·∫°y:**
```bash
npm run dev
```

**Ph·∫£i th·∫•y:**
1. Browser h·ªèi quy·ªÅn camera ‚Üí Nh·∫•n "Allow"
2. Video live t·ª´ webcam hi·ªÉn th·ªã
3. Badge "LIVE" ƒë·ªè g√≥c tr√™n ph·∫£i

### ‚úÖ Checkpoint 4
- [Y] Webcam b·∫≠t ƒë∆∞·ª£c
- [Y] Video hi·ªÉn th·ªã real-time
- [Y] Badge "LIVE" xu·∫•t hi·ªán

---

## B∆∞·ªõc 5: Integrate AI Detection

### 5.1. Gi·∫£i Th√≠ch C√°ch Ho·∫°t ƒê·ªông

```
Video Stream (30 FPS)
    ‚Üì
M·ªói frame ‚Üí AI detect
    ‚Üì
V·∫Ω bounding boxes l√™n video
    ‚Üì
Show s·ªë l∆∞·ª£ng xe
```

### 5.2. T·∫°o Detection Overlay Component

**File: `src/components/LiveDetection.tsx`** (T·∫†O M·ªöI)

```typescript
import { useEffect, useRef, useState } from 'react';
import { aiDetection, Detection } from '../services/ai/aiDetection';

interface LiveDetectionProps {
  videoElement: HTMLVideoElement;
}

export function LiveDetection({ videoElement }: LiveDetectionProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [detections, setDetections] = useState<Detection[]>([]);
  const [fps, setFps] = useState(0);
  
  useEffect(() => {
    let animationId: number;
    let lastTime = Date.now();
    let frameCount = 0;
    
    const detectLoop = async () => {
      if (!videoElement || !canvasRef.current) return;
      
      try {
        // 1. Detect vehicles
        const vehicles = await aiDetection.detectVehicles(videoElement);
        setDetections(vehicles);
        
        // 2. Draw bounding boxes
        drawDetections(vehicles);
        
        // 3. Calculate FPS
        frameCount++;
        const now = Date.now();
        if (now - lastTime >= 1000) {
          setFps(frameCount);
          frameCount = 0;
          lastTime = now;
        }
      } catch (error) {
        console.error('Detection error:', error);
      }
      
      // 4. Loop
      animationId = requestAnimationFrame(detectLoop);
    };
    
    const drawDetections = (vehicles: Detection[]) => {
      const canvas = canvasRef.current;
      if (!canvas) return;
      
      const ctx = canvas.getContext('2d')!;
      
      // Clear canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      // Draw each vehicle
      vehicles.forEach(vehicle => {
        const [x, y, width, height] = vehicle.bbox;
        
        // Bounding box
        ctx.strokeStyle = '#00ff00';
        ctx.lineWidth = 3;
        ctx.strokeRect(x, y, width, height);
        
        // Label background
        ctx.fillStyle = '#00ff00';
        ctx.fillRect(x, y - 25, 200, 25);
        
        // Label text
        ctx.fillStyle = '#000';
        ctx.font = '16px Arial';
        ctx.fillText(
          `${vehicle.class} (${Math.round(vehicle.score * 100)}%)`,
          x + 5,
          y - 7
        );
      });
    };
    
    detectLoop();
    
    return () => {
      if (animationId) {
        cancelAnimationFrame(animationId);
      }
    };
  }, [videoElement]);
  
  return (
    <div>
      <canvas
        ref={canvasRef}
        width={videoElement.videoWidth || 1280}
        height={videoElement.videoHeight || 720}
        className="absolute top-0 left-0 pointer-events-none"
      />
      
      <div className="mt-4 p-4 bg-gray-900 text-white rounded-lg">
        <div className="flex justify-between items-center">
          <div>
            <span className="text-2xl font-bold">{detections.length}</span>
            <span className="ml-2">vehicles detected</span>
          </div>
          <div className="text-sm text-gray-400">
            FPS: {fps}
          </div>
        </div>
        
        {detections.length > 0 && (
          <div className="mt-2 text-sm">
            {detections.map((d, i) => (
              <div key={i} className="flex justify-between">
                <span>{d.class}</span>
                <span>{Math.round(d.score * 100)}%</span>
              </div>
            ))}
          </div>
        )}
      </div>
    </div>
  );
}
```

### 5.3. Update LiveViewPage

**File: `src/pages/LiveViewPage.tsx`** (UPDATE)

```typescript
import { useState, useEffect } from 'react';
import { LiveCamera } from '../components/LiveCamera';
import { LiveDetection } from '../components/LiveDetection';
import { aiDetection } from '../services/ai/aiDetection';

export function LiveViewPage() {
  const [videoElement, setVideoElement] = useState<HTMLVideoElement | null>(null);
  const [modelLoaded, setModelLoaded] = useState(false);
  
  useEffect(() => {
    // Load AI model
    aiDetection.loadModel().then(() => {
      setModelLoaded(true);
    });
  }, []);
  
  const handleStreamReady = (stream: MediaStream) => {
    // Get video element
    const video = document.querySelector('video');
    if (video) {
      setVideoElement(video);
    }
  };
  
  return (
    <div className="p-8">
      <h1 className="text-3xl font-bold mb-4">
        üöó Live Vehicle Detection
      </h1>
      
      {!modelLoaded ? (
        <div className="p-4 bg-yellow-50 text-yellow-700 rounded">
          ‚è≥ Loading AI model... Please wait.
        </div>
      ) : (
        <div className="relative">
          <LiveCamera onStreamReady={handleStreamReady} />
          
          {videoElement && (
            <LiveDetection videoElement={videoElement} />
          )}
        </div>
      )}
    </div>
  );
}
```

**Ch·∫°y:**
```bash
npm run dev
```

**Ph·∫£i th·∫•y:**
1. Camera live
2. Bounding boxes xanh quanh xe (n·∫øu c√≥ xe trong camera)
3. Count s·ªë xe
4. FPS counter

### ‚úÖ Checkpoint 5
- [Y] AI detect ƒë∆∞·ª£c xe
- [Y] Bounding boxes hi·ªÉn th·ªã
- [Y] S·ªë l∆∞·ª£ng xe hi·ªÉn th·ªã ch√≠nh x√°c

---

## B∆∞·ªõc 6: Save Results to Firestore

### 6.1. Gi·∫£i Th√≠ch

**L∆∞u g√¨ v√†o Firestore?**
- CH·ªà l∆∞u **k·∫øt qu·∫£ detection** (text, numbers)
- KH√îNG l∆∞u video/·∫£nh (ƒë·ªÉ ti·∫øt ki·ªám storage)

**L∆∞u nh∆∞ th·∫ø n√†o?**
- M·ªói 5 gi√¢y ‚Üí Capture snapshot k·∫øt qu·∫£
- Save v√†o Firestore collection `detections`

### 6.2. Define Types

**File: `src/types/firestore.types.ts`** (T·∫†O M·ªöI)

```typescript
import { Timestamp } from 'firebase/firestore';

/**
 * Detection Result trong Firestore
 */
export interface DetectionRecord {
  id: string;
  timestamp: Timestamp;
  vehicleCount: number;
  vehicles: {
    type: string;    // 'car', 'truck', etc
    confidence: number;
    bbox: [number, number, number, number];
  }[];
  cameraId: string;
}
```

### 6.3. T·∫°o Service Save to Firestore

**File: `src/services/detectionService.ts`** (T·∫†O M·ªöI)

```typescript
import { collection, addDoc, Timestamp } from 'firebase/firestore';
import { db } from '../config/firebase';
import { Detection } from './ai/aiDetection';

/**
 * Save detection results to Firestore
 */
export async function saveDetectionRecord(
  vehicles: Detection[],
  cameraId: string = 'CAM_001'
): Promise<void> {
  try {
    await addDoc(collection(db, 'detections'), {
      timestamp: Timestamp.now(),
      vehicleCount: vehicles.length,
      vehicles: vehicles.map(v => ({
        type: v.class,
        confidence: v.score,
        bbox: v.bbox
      })),
      cameraId: cameraId
    });
    
    console.log('‚úÖ Saved detection:', vehicles.length, 'vehicles');
  } catch (error) {
    console.error('‚ùå Failed to save detection:', error);
  }
}
```

### 6.4. Auto Save Every 5 Seconds

**File: `src/components/LiveDetection.tsx`** (UPDATE)

```typescript
// ... existing imports ...
import { saveDetectionRecord } from '../services/detectionService';

export function LiveDetection({ videoElement }: LiveDetectionProps) {
  // ... existing states ...
  const [lastSaveTime, setLastSaveTime] = useState(Date.now());
  
  useEffect(() => {
    // ... existing code ...
    
    const detectLoop = async () => {
      // ... existing detection code ...
      
      const vehicles = await aiDetection.detectVehicles(videoElement);
      setDetections(vehicles);
      
      // Auto save m·ªói 5 gi√¢y
      const now = Date.now();
      if (now - lastSaveTime >= 5000) { // 5 seconds
        if (vehicles.length > 0) {
          await saveDetectionRecord(vehicles);
          setLastSaveTime(now);
        }
      }
      
      // ... rest of code ...
    };
    
    // ... rest of useEffect ...
  }, [videoElement, lastSaveTime]);
  
  // ... rest of component ...
}
```

**Ch·∫°y:**
```bash
npm run dev
```

**Ki·ªÉm tra Firestore:**
1. V√†o Firebase Console
2. Firestore Database
3. Collection `detections`
4. Ph·∫£i th·∫•y documents m·ªõi m·ªói 5 gi√¢y (khi c√≥ xe)

### ‚úÖ Checkpoint 6
- [Y] Detections ƒë∆∞·ª£c save v√†o Firestore
- [Y] Console log "Saved detection"
- [Y] Firebase Console hi·ªÉn th·ªã data

---

## B∆∞·ªõc 7: Build Dashboard

### 7.1. History Page (Xem L·ªãch S·ª≠)

**File: `src/pages/HistoryPage.tsx`** (T·∫†O M·ªöI)

```typescript
import { useEffect, useState } from 'react';
import { collection, query, orderBy, limit, getDocs } from 'firebase/firestore';
import { db } from '../config/firebase';
import { format } from 'date-fns';

interface DetectionRecord {
  id: string;
  timestamp: Date;
  vehicleCount: number;
  vehicles: any[];
}

export function HistoryPage() {
  const [records, setRecords] = useState<DetectionRecord[]>([]);
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    const fetchHistory = async () => {
      try {
        const q = query(
          collection(db, 'detections'),
          orderBy('timestamp', 'desc'),
          limit(50)
        );
        
        const snapshot = await getDocs(q);
        const data = snapshot.docs.map(doc => ({
          id: doc.id,
          ...doc.data(),
          timestamp: doc.data().timestamp.toDate()
        })) as DetectionRecord[];
        
        setRecords(data);
        setLoading(false);
      } catch (error) {
        console.error('Error fetching history:', error);
        setLoading(false);
      }
    };
    
    fetchHistory();
  }, []);
  
  if (loading) {
    return <div className="p-8">Loading...</div>;
  }
  
  return (
    <div className="p-8">
      <h1 className="text-3xl font-bold mb-4">
        üìä Detection History
      </h1>
      
      <div className="space-y-4">
        {records.map(record => (
          <div 
            key={record.id}
            className="p-4 bg-white border rounded-lg shadow"
          >
            <div className="flex justify-between items-center">
              <div>
                <div className="font-bold">
                  {record.vehicleCount} vehicles
                </div>
                <div className="text-sm text-gray-600">
                  {format(record.timestamp, 'dd/MM/yyyy HH:mm:ss')}
                </div>
              </div>
              
              <div className="text-sm">
                {record.vehicles.map((v, i) => (
                  <div key={i}>
                    {v.type}: {Math.round(v.confidence * 100)}%
                  </div>
                ))}
              </div>
            </div>
          </div>
        ))}
      </div>
    </div>
  );
}
```

### 7.2. Stats Page (Th·ªëng K√™)

**File: `src/pages/StatsPage.tsx`** (T·∫†O M·ªöI)

```typescript
import { useEffect, useState } from 'react';
import { collection, getDocs } from 'firebase/firestore';
import { db } from '../config/firebase';

export function StatsPage() {
  const [stats, setStats] = useState({
    totalDetections: 0,
    totalVehicles: 0,
    avgVehicles: 0
  });
  
  useEffect(() => {
    const fetchStats = async () => {
      const snapshot = await getDocs(collection(db, 'detections'));
      
      const totalDetections = snapshot.size;
      const totalVehicles = snapshot.docs.reduce(
        (sum, doc) => sum + doc.data().vehicleCount, 
        0
      );
      const avgVehicles = totalDetections > 0 
        ? totalVehicles / totalDetections 
        : 0;
      
      setStats({
        totalDetections,
        totalVehicles,
        avgVehicles
      });
    };
    
    fetchStats();
  }, []);
  
  return (
    <div className="p-8">
      <h1 className="text-3xl font-bold mb-4">üìà Statistics</h1>
      
      <div className="grid grid-cols-3 gap-4">
        <div className="p-6 bg-blue-50 rounded-lg">
          <div className="text-4xl font-bold text-blue-600">
            {stats.totalDetections}
          </div>
          <div className="text-gray-600">Total Detections</div>
        </div>
        
        <div className="p-6 bg-green-50 rounded-lg">
          <div className="text-4xl font-bold text-green-600">
            {stats.totalVehicles}
          </div>
          <div className="text-gray-600">Total Vehicles</div>
        </div>
        
        <div className="p-6 bg-purple-50 rounded-lg">
          <div className="text-4xl font-bold text-purple-600">
            {stats.avgVehicles.toFixed(1)}
          </div>
          <div className="text-gray-600">Avg Vehicles/Detection</div>
        </div>
      </div>
    </div>
  );
}
```

### 7.3. Setup Router

**File: `src/App.tsx`** (FINAL UPDATE)

```typescript
import { BrowserRouter, Routes, Route, Link } from 'react-router-dom';
import { LiveViewPage } from './pages/LiveViewPage';
import { HistoryPage } from './pages/HistoryPage';
import { StatsPage } from './pages/StatsPage';

function App() {
  return (
    <BrowserRouter>
      <div className="min-h-screen bg-gray-50">
        {/* Navigation */}
        <nav className="bg-white shadow-md p-4 mb-8">
          <div className="max-w-7xl mx-auto flex gap-4">
            <Link to="/" className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600">
              üé• Live View
            </Link>
            <Link to="/history" className="px-4 py-2 bg-gray-200 rounded hover:bg-gray-300">
              üìä History
            </Link>
            <Link to="/stats" className="px-4 py-2 bg-gray-200 rounded hover:bg-gray-300">
              üìà Stats
            </Link>
          </div>
        </nav>
        
        {/* Routes */}
        <Routes>
          <Route path="/" element={<LiveViewPage />} />
          <Route path="/history" element={<HistoryPage />} />
          <Route path="/stats" element={<StatsPage />} />
        </Routes>
      </div>
    </BrowserRouter>
  );
}

export default App;
```

### ‚úÖ Checkpoint 7
- [Y] Live View ho·∫°t ƒë·ªông
- [Y] History page hi·ªÉn th·ªã records
- [Y] Stats page hi·ªÉn th·ªã th·ªëng k√™
- [Y] Navigation ho·∫°t ƒë·ªông

---

## B∆∞·ªõc 8: Testing & Polish

### 8.1. Test Checklist

- [ ] **Camera**: Webcam b·∫≠t ƒë∆∞·ª£c
- [ ] **AI**: Detect xe ch√≠nh x√°c
- [ ] **Real-time**: Bounding boxes m∆∞·ª£t
- [ ] **Save**: Data v√†o Firestore
- [ ] **History**: Hi·ªÉn th·ªã ƒë√∫ng
- [ ] **Stats**: T√≠nh to√°n ƒë√∫ng
- [ ] **Navigation**: Chuy·ªÉn trang OK

### 8.2. Performance Tips

```typescript
// Gi·∫£m t·∫ßn su·∫•t detect (n·∫øu lag)
const DETECT_INTERVAL = 200; // ms (5 FPS thay v√¨ 30 FPS)

// Trong detectLoop:
setTimeout(() => detectLoop(), DETECT_INTERVAL);
// Thay v√¨: requestAnimationFrame(detectLoop);
```

### 8.3. Deploy (Optional)

```bash
# Build
npm run build

# Deploy l√™n Vercel/Netlify (mi·ªÖn ph√≠)
# Upload folder dist/
```

---

## üéâ HO√ÄN T·∫§T!

### B·∫°n ƒê√£ C√≥:

‚úÖ Live camera v·ªõi WebRTC  
‚úÖ AI detection (TensorFlow.js)  
‚úÖ Firestore database  
‚úÖ Dashboard v·ªõi History & Stats  
‚úÖ **100% MI·ªÑN PH√ç**  

### Next Steps (N·∫øu Mu·ªën N√¢ng C·∫•p):

1. ‚úÖ Th√™m alerts (xe ƒë·ªó sai ch·ªó) ‚Äì xem trang üö® Alerts + auto log v√†o Firestore
2. Export reports (PDF, Excel)
3. ‚úÖ Multiple cameras ‚Äì Live View ch·ªçn camera + trang üó∫Ô∏è Multi Cam
4. ‚úÖ Admin authentication ‚Äì Firebase Email/Password + Protected Routes

### üîß Feature Configuration

- **Admin Auth**: T·∫°o Firebase Authentication (Email/Password) user ‚Üí c·∫•u h√¨nh env `VITE_FIREBASE_*` ‚Üí truy c·∫≠p `/login`. Coaches History/Stats/Alerts/Multi-cam now require login.
- **Multiple Cameras**: Ch·ªânh `frontend/src/config/cameras.ts` ƒë·ªÉ th√™m ID/camera m·ªõi. Live View dropdown + trang `Multi Cam` s·∫Ω t·ª± c·∫≠p nh·∫≠t.
- **Alerts (xe ƒë·ªó sai ch·ªó)**: ƒê·ªãnh nghƒ©a allowed/restricted boxes trong `frontend/src/config/parkingRules.ts`. Khi l∆∞u detection, h·ªá th·ªëng log alert v√†o collection `parkingAlerts` + hi·ªÉn th·ªã tr√™n trang üö® Alerts. 

---

**üéä Ch√∫c m·ª´ng! B·∫°n ƒë√£ ho√†n th√†nh Smart Parking System!** üöó‚ú®

